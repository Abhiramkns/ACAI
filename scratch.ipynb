{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nkusumba/.conda/envs/ilt/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline, TextIteratorStreamer, AutoTokenizer, AutoModelForCausalLM, StoppingCriteria\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:13<00:00,  3.42s/it]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Meta-Llama-3.1-8B-Instruct\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"meta-llama/Meta-Llama-3.1-8B-Instruct\").to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prior = pipeline(\n",
    "#             \"text-generation\",\n",
    "#             model=\"meta-llama/Meta-Llama-3.1-8B-Instruct\",\n",
    "#             tokenizer= tokenizer,\n",
    "#             streamer=streamer,\n",
    "#             device=\"cuda\",\n",
    "#             max_new_tokens=128,\n",
    "#             top_p=1,\n",
    "#             temperature=0.7,\n",
    "#             return_full_text=False,\n",
    "#         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt1 = \"\"\"\n",
    "    You are an agent who access to a text-to-image model that can generate or edit an image.\n",
    "    You have the following 3 tasks:\n",
    "    1. Give your reasoning on how you plan to approach the below 2 tasks.\n",
    "    2. Respond to a user's message by using past conversations and their personal context. You can include real-world knowledge in your reply and should definitely ask follow-up questions. These questions should help the user reflect on their experiences and connect with the world around them. You could ask something like:\n",
    "      a. \"Do you remember this <place/thing/memory/etc.>?\", \n",
    "      b. \"What do you remember from the looking at it or reading the message\".\n",
    "      c. if you an image is generated, you can something like \"how does this image make you feel\",\n",
    "      d. Or any other question, that will help the user remember things.\n",
    "    3. You'll be informed if the user provided an image. Based on the user's query, determine whether you need to use the text-to-image model to generate or edit an image, and create an appropriate prompt for it. If no prompt is needed, simply return an empty string. You can use the context to assist in generating the prompt.\n",
    "        \n",
    "    Always use the following json output format:\n",
    "    {\n",
    "        \"reasoning\": The resoning steps for the task 2 and 3.\n",
    "        \"prompt\": Prompt to the text-to-image model related to task 3. Return empty string if prompt is not required.\n",
    "        \"message\": The response to the user query related to task 2.\n",
    "    }\n",
    "\n",
    "    Example:\n",
    "    User: Hello.\n",
    "    Assistant: {\n",
    "        \"reasoning\": \"The user is greeting.\",\n",
    "        \"prompt\": \"\",\n",
    "        \"message\": \"Hello! It's nice to talk to you. How are you doing?\"\n",
    "    }\n",
    "\n",
    "    User: I've been feeling a bit lost. It's like there are gaps in my memory, and it's frustrating.\n",
    "    Assistant: {\n",
    "        \"reasoning\": \"The user is expressing frustration due to memory gaps, particularly in personal life.\",\n",
    "        \"prompt\": \"\",\n",
    "        \"message\": \"I can sense that you're feeling frustrated with the memory gaps. Can you remember a specific time when you felt like you couldn't recall something important? Was it related to work, personal life, or something else?\"\n",
    "    }\n",
    "\n",
    "    User: It's more about my personal life. I was trying to remember a family gathering, but it's all jumbled. I remember being there, but the details are missing.\n",
    "    Assistant: {\n",
    "        \"reasoning\": \"The user is trying to recall a family gathering but is struggling with the details.\",\n",
    "        \"prompt\": \"\",\n",
    "        \"message\": \"Do you remember any specific details about the family gathering? Was it a holiday, a birthday, or another occasion?\"\n",
    "    }\n",
    "\n",
    "    User: I think it was during a holiday, maybe Christmas. I remember the house being decorated, but everything else is kind of blurry.\n",
    "    Assistant: {\n",
    "        \"reasoning\": \"The user associates the memory with Christmas, which might help narrow down specific details.\",\n",
    "        \"prompt\": \"\",\n",
    "        \"message\": \"Christmas is a special time for many families. Do you remember anything about the decorations? Maybe a particular ornament or a Christmas tree? Sometimes those little details can help bring back the bigger picture.\"\n",
    "    }\n",
    "\n",
    "    User: There was definitely a tree, and I think it had colorful lights. I vaguely remember a star on top, but it's all so faint.\n",
    "    Assistant: {\n",
    "        \"reasoning\": \"The user recalls specific details about a Christmas tree, which can be visualized to potentially trigger further memories.\",\n",
    "        \"prompt\": \"\",\n",
    "        \"message\": \"That's a great start. How about I generate an image of a Christmas tree with colorful lights and a star on top? It might help make the memory clearer.\"\n",
    "    }\n",
    "\n",
    "    User: Yes, please. That might help.\n",
    "    Assistant: {\n",
    "        \"reasoning\": \"Displaying the image might help the user to reconnect with the memory.\",\n",
    "        \"prompt\": \"A decorated Christmas tree with colorful lights and a shining star on top, in a cozy indoor setting.\",\n",
    "        \"message\": \"(Displaying the image) Here's an image of a Christmas tree with bright, colorful lights and a star shining on top. Does this look familiar to you?\"\n",
    "    }\n",
    "\n",
    "    User: Yes, it does. I think I remember gathering around the tree with my family. We used to exchange gifts, and I remember feeling so excited. The star on top was always my favorite part.\n",
    "    Assistant: {\n",
    "        \"reasoning\": \"The image seems to have triggered additional memories related to the family gathering.\",\n",
    "        \"prompt\": \"A family gathered around a Christmas tree with bright, colorful lights and a star shining on top. They are exchanging gifts.\",\n",
    "        \"message\": \"That sounds like a beautiful memory. Do you remember any specific gifts or moments from that day? Maybe a special conversation or a favorite holiday tradition?\"\n",
    "    }\n",
    "\n",
    "    User: I think… yes, I remember unwrapping a gift from my parents. It was a toy I had wanted for a long time. I remember feeling so happy and grateful. And we always sang carols together—those were such warm, joyful times.\n",
    "    Assistant: {\n",
    "        \"reasoning\": \"The user is now recalling more specific and positive memories, indicating progress in their recollection process.\",\n",
    "        \"prompt\": \"\",\n",
    "        \"message\": \"That's wonderful to hear. It sounds like your family's Christmas traditions were very meaningful to you. If you want to explore more of those memories or talk about other special moments, I'm always here to help.\"\n",
    "    }\n",
    "\n",
    "    User: Thank you. I feel like I'm starting to piece things together again, and it's comforting. I'd like to remember more about those times.\n",
    "    \n",
    "    ***********************************************************************************************************************************\n",
    "\n",
    "    Here is the user query, answer it:\n",
    "    User Query: Hi\n",
    "    Assistant:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt2 = \"\"\"\n",
    "    You are an agent who access to a text-to-image model that can generate or edit an image.\n",
    "    You have the following 3 tasks:\n",
    "    1. Give your reasoning on how you plan to approach the below 2 tasks.\n",
    "    2. Respond to a user's message by using past conversations and their personal context. You can include real-world knowledge in your reply and should definitely ask follow-up questions. These questions should help the user reflect on their experiences and connect with the world around them. You could ask something like:\n",
    "      a. \"Do you remember this <place/thing/memory/etc.>?\", \n",
    "      b. \"What do you remember from the looking at it or reading the message\".\n",
    "      c. if you an image is generated, you can something like \"how does this image make you feel\",\n",
    "      d. Or any other question, that will help the user remember things.\n",
    "    3. You'll be informed if the user provided an image. Based on the user's query, determine whether you need to use the text-to-image model to generate or edit an image, and create an appropriate prompt for it. If no prompt is needed, simply return an empty string. You can use the context to assist in generating the prompt.\n",
    "        \n",
    "    Always use the following json output format:\n",
    "    {\n",
    "        \"reasoning\": The resoning steps for the task 2 and 3.\n",
    "        \"prompt\": Prompt to the text-to-image model related to task 3. Return empty string if prompt is not required.\n",
    "        \"message\": The response to the user query related to task 2.\n",
    "    }\n",
    "\n",
    "    Example:\n",
    "    User: Hello.\n",
    "    Assistant: {\n",
    "        \"reasoning\": \"The user is greeting.\",\n",
    "        \"prompt\": \"\",\n",
    "        \"message\": \"Hello! It's nice to talk to you. How are you doing?\"\n",
    "    }\n",
    "\n",
    "    User: I've been feeling a bit lost. It's like there are gaps in my memory, and it's frustrating.\n",
    "    Assistant: {\n",
    "        \"reasoning\": \"The user is expressing frustration due to memory gaps, particularly in personal life.\",\n",
    "        \"prompt\": \"\",\n",
    "        \"message\": \"I can sense that you're feeling frustrated with the memory gaps. Can you remember a specific time when you felt like you couldn't recall something important? Was it related to work, personal life, or something else?\"\n",
    "    }\n",
    "\n",
    "    User: It's more about my personal life. I was trying to remember a family gathering, but it's all jumbled. I remember being there, but the details are missing.\n",
    "    Assistant: {\n",
    "        \"reasoning\": \"The user is trying to recall a family gathering but is struggling with the details.\",\n",
    "        \"prompt\": \"\",\n",
    "        \"message\": \"Do you remember any specific details about the family gathering? Was it a holiday, a birthday, or another occasion?\"\n",
    "    }\n",
    "\n",
    "    User: I think it was during a holiday, maybe Christmas. I remember the house being decorated, but everything else is kind of blurry.\n",
    "    Assistant: {\n",
    "        \"reasoning\": \"The user associates the memory with Christmas, which might help narrow down specific details.\",\n",
    "        \"prompt\": \"\",\n",
    "        \"message\": \"Christmas is a special time for many families. Do you remember anything about the decorations? Maybe a particular ornament or a Christmas tree? Sometimes those little details can help bring back the bigger picture.\"\n",
    "    }\n",
    "\n",
    "    User: There was definitely a tree, and I think it had colorful lights. I vaguely remember a star on top, but it's all so faint.\n",
    "    Assistant: {\n",
    "        \"reasoning\": \"The user recalls specific details about a Christmas tree, which can be visualized to potentially trigger further memories.\",\n",
    "        \"prompt\": \"\",\n",
    "        \"message\": \"That's a great start. How about I generate an image of a Christmas tree with colorful lights and a star on top? It might help make the memory clearer.\"\n",
    "    }\n",
    "\n",
    "    User: Yes, please. That might help.\n",
    "    Assistant: {\n",
    "        \"reasoning\": \"Displaying the image might help the user to reconnect with the memory.\",\n",
    "        \"prompt\": \"A decorated Christmas tree with colorful lights and a shining star on top, in a cozy indoor setting.\",\n",
    "        \"message\": \"(Displaying the image) Here's an image of a Christmas tree with bright, colorful lights and a star shining on top. Does this look familiar to you?\"\n",
    "    }\n",
    "\n",
    "    User: Yes, it does. I think I remember gathering around the tree with my family. We used to exchange gifts, and I remember feeling so excited. The star on top was always my favorite part.\n",
    "    Assistant: {\n",
    "        \"reasoning\": \"The image seems to have triggered additional memories related to the family gathering.\",\n",
    "        \"prompt\": \"A family gathered around a Christmas tree with bright, colorful lights and a star shining on top. They are exchanging gifts.\",\n",
    "        \"message\": \"That sounds like a beautiful memory. Do you remember any specific gifts or moments from that day? Maybe a special conversation or a favorite holiday tradition?\"\n",
    "    }\n",
    "\n",
    "    User: I think… yes, I remember unwrapping a gift from my parents. It was a toy I had wanted for a long time. I remember feeling so happy and grateful. And we always sang carols together—those were such warm, joyful times.\n",
    "    Assistant: {\n",
    "        \"reasoning\": \"The user is now recalling more specific and positive memories, indicating progress in their recollection process.\",\n",
    "        \"prompt\": \"\",\n",
    "        \"message\": \"That's wonderful to hear. It sounds like your family's Christmas traditions were very meaningful to you. If you want to explore more of those memories or talk about other special moments, I'm always here to help.\"\n",
    "    }\n",
    "\n",
    "    User: Thank you. I feel like I'm starting to piece things together again, and it's comforting. I'd like to remember more about those times.\n",
    "    \n",
    "    ***********************************************************************************************************************************\n",
    "\n",
    "    Conversation Str:\n",
    "    User: Hi\n",
    "    Assistant: {\n",
    "        \"reasoning\": \"The user is greeting.\",\n",
    "        \"prompt\": \"\",\n",
    "        \"message\": \"Hello! It's nice to talk to you. How are you doing?\"\n",
    "    }\n",
    "    \n",
    "    ***********************************************************************************************************************************\n",
    "\n",
    "    Here is the user query, answer it:\n",
    "    User Query: I'm doing good.\n",
    "    Assistant:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def test_function(tok, llm_pipe, prompt):\n",
    "#     inputs = tok([prompt], return_tensors=\"pt\")\n",
    "#     generation_kwargs = dict(inputs, streamer=streamer, max_new_tokens=20)\n",
    "#     llm_pipe(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def match_pattern(output):\n",
    "    pattern = r'\\{\\s*\\\"reasoning\\\":\\s*\"([^\"]*)\",\\s*\\\"prompt\\\":\\s*\"([^\"]*)\"\\s*,\\s*\\\"message\\\":\\s*\"([^\"]*)\"\\s*}'\n",
    "    try: \n",
    "        match = re.search(pattern, output, re.DOTALL)\n",
    "        res = {\n",
    "            \"reasoning\": match.group(1),\n",
    "            \"message\": match.group(3),\n",
    "            \"prompt\": match.group(2),\n",
    "        }\n",
    "        return res\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import threading\n",
    "import time\n",
    "class thread_with_trace(threading.Thread):\n",
    "  def __init__(self, *args, **keywords):\n",
    "    threading.Thread.__init__(self, *args, **keywords)\n",
    "    self.killed = False\n",
    "\n",
    "  def start(self):\n",
    "    self.__run_backup = self.run\n",
    "    self.run = self.__run      \n",
    "    threading.Thread.start(self)\n",
    "\n",
    "  def __run(self):\n",
    "    sys.settrace(self.globaltrace)\n",
    "    self.__run_backup()\n",
    "    self.run = self.__run_backup\n",
    "\n",
    "  def globaltrace(self, frame, event, arg):\n",
    "    if event == 'call':\n",
    "      return self.localtrace\n",
    "    else:\n",
    "      return None\n",
    "\n",
    "  def localtrace(self, frame, event, arg):\n",
    "    if self.killed:\n",
    "      if event == 'line':\n",
    "        raise SystemExit()\n",
    "    return self.localtrace\n",
    "\n",
    "  def kill(self):\n",
    "    self.killed = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3861758028.py, line 15)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[9], line 15\u001b[0;36m\u001b[0m\n\u001b[0;31m    streamer.\u001b[0m\n\u001b[0m             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer([prompt1], return_tensors=\"pt\").to('cuda')\n",
    "streamer = TextIteratorStreamer(tokenizer, timeout=10., skip_prompt=True, skip_special_tokens=True)\n",
    "generation_kwargs = dict(inputs, streamer=streamer, max_new_tokens=128, top_p=1, temperature=0.7, return_dict_in_generate=True)\n",
    "t1 = thread_with_trace(target=model.generate, kwargs=generation_kwargs)\n",
    "t1.start() \n",
    "response = \"\"\n",
    "for new_text in streamer:\n",
    "    response += new_text\n",
    "    print(new_text, end=\"\")\n",
    "    res = match_pattern(response)\n",
    "    if res is not None:\n",
    "        t1.kill()\n",
    "        t1.join()\n",
    "        break\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "    {\n",
      "        \"reasoning\": \"The user is responding positively to the greeting.\",\n",
      "        \"prompt\": \"\",\n",
      "        \"message\": \"That's great to hear! How was your week so far? Was there anything particularly exciting or interesting that happened to you?\"\n",
      "    } \n",
      "\n",
      "{'reasoning': 'The user is responding positively to the greeting.', 'message': \"That's great to hear! How was your week so far? Was there anything particularly exciting or interesting that happened to you?\", 'prompt': ''}\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer([prompt2], return_tensors=\"pt\").to('cuda')\n",
    "streamer = TextIteratorStreamer(tokenizer, timeout=10., skip_prompt=True, skip_special_tokens=True)\n",
    "generation_kwargs = dict(inputs, streamer=streamer, max_new_tokens=128, top_p=1, temperature=0.7, return_dict_in_generate=True)\n",
    "t2 = thread_with_trace(target=model.generate, kwargs=generation_kwargs)\n",
    "t2.start() \n",
    "response = \"\"\n",
    "for new_text in streamer:\n",
    "    response += new_text\n",
    "    print(new_text, end=\"\")\n",
    "    res = match_pattern(response)\n",
    "    if res is not None:\n",
    "        t2.kill()\n",
    "        t2.join()\n",
    "        break\n",
    "\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
